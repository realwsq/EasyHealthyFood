//
//  ViewController.swift
//  Simple Image Recognition App
//
//  Created by 王书琪 on 2017/10/9.
//  Copyright © 2017年 wsq. All rights reserved.
//
import UIKit
import AVKit
import CoreML
import Vision

class FirstViewController: UIViewController, UINavigationControllerDelegate, AVCaptureVideoDataOutputSampleBufferDelegate {
    
//    @IBOutlet weak var imageView: UIImageView!
//    @IBOutlet weak var classifier: UILabel!
//
//    var model: Inceptionv3!
    
    var photoresults : [[VNClassificationObservation]] = []
    var results : [VNClassificationObservation] = []
    
    let identifierLabel: UILabel = {
        let label = UILabel()
        label.backgroundColor = .white
        label.textAlignment = .center
        
//        This line of code disables the button’s automatically generated constraints. When you programmatically instantiate a view, its translatesAutoresizingMaskIntoConstraints property defaults to true. This tells the layout engine to create constraints that define the view’s size and position based on the view’s frame and autoresizingmask properties. Typically, when you are using Auto Layout, you want to replace these autogenerated constraints with your own. To remove the autogenerated constraints, set the translatesAutoresizingMaskIntoConstraints property to false.
        label.translatesAutoresizingMaskIntoConstraints = false
        return label
    }()
    let takephotobutton: UIButton = {
        let btn = UIButton(type: .system)
        btn.setTitle("take", for: .normal)
        btn.addTarget(self, action: #selector(takephototapped), for: .touchUpInside)
        
        btn.translatesAutoresizingMaskIntoConstraints = false
        return btn
    }()
    let confirmbutton: UIButton = {
        let btn = UIButton(type: .system)
        btn.setTitle("confirm", for: .normal)
        btn.addTarget(self, action: #selector(confirmtapped), for: .touchUpInside)
        
        btn.translatesAutoresizingMaskIntoConstraints = false
        return btn
    }()
    
    override func viewDidLoad() {
        super.viewDidLoad()
        // Do any additional setup after loading the view, typically from a nib.
        
        // here is where we start up the camera
        // for more details visit: https://www.letsbuildthatapp.com/course_video?id=1252
        let captureSession = AVCaptureSession()
        captureSession.sessionPreset = .photo
        
        guard let captureDevice = AVCaptureDevice.default(for: .video) else { return }
        guard let input = try? AVCaptureDeviceInput(device: captureDevice) else { return }
        captureSession.addInput(input)
        
        captureSession.startRunning()
        
        let previewLayer = AVCaptureVideoPreviewLayer(session: captureSession)
        view.layer.addSublayer(previewLayer)
        previewLayer.frame = view.frame
        
        let dataOutput = AVCaptureVideoDataOutput()
        dataOutput.setSampleBufferDelegate(self, queue: DispatchQueue(label: "videoQueue"))
        captureSession.addOutput(dataOutput)
        
//        setupIdentifierConfidenceLabel()
        setupIdentifierTakephotobutton()
        setupIdentifierConfirmbutton()
    }
    
    fileprivate func setupIdentifierConfidenceLabel() {
        view.addSubview(identifierLabel)
        identifierLabel.bottomAnchor.constraint(equalTo: view.bottomAnchor, constant: -40).isActive = true
        identifierLabel.leftAnchor.constraint(equalTo: view.leftAnchor).isActive = true
        identifierLabel.rightAnchor.constraint(equalTo: view.rightAnchor).isActive = true
        identifierLabel.heightAnchor.constraint(equalToConstant: 50).isActive = true
    }
    fileprivate func setupIdentifierTakephotobutton() {
        view.addSubview(takephotobutton)
        takephotobutton.bottomAnchor.constraint(equalTo: view.bottomAnchor, constant: -40).isActive = true
//        takephotobutton.leftAnchor.constraint(equalTo: view.leftAnchor).isActive = true
//        takephotobutton.rightAnchor.constraint(equalTo: view.rightAnchor).isActive = true
        takephotobutton.heightAnchor.constraint(equalToConstant: 50).isActive = true
//        takephotobutton.center.x = self.view.center.x
        takephotobutton.centerXAnchor.constraint(equalTo: view.centerXAnchor).isActive = true
    }
    fileprivate func setupIdentifierConfirmbutton() {
        view.addSubview(confirmbutton)
        confirmbutton.bottomAnchor.constraint(equalTo: view.bottomAnchor, constant: -40).isActive = true
//        confirmbutton.leftAnchor.constraint(equalTo: view.leftAnchor).isActive = true
        confirmbutton.rightAnchor.constraint(equalTo: view.rightAnchor).isActive = true
        confirmbutton.heightAnchor.constraint(equalToConstant: 50).isActive = true
//        takephotobutton.center.x = self.view.center.x
    }
    
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        //        print("Camera was able to capture a frame:", Date())
        
        guard let pixelBuffer: CVPixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }
        
        // !!!Important
        // make sure to go download the models at https://developer.apple.com/machine-learning/ scroll to the bottom
        guard let model = try? VNCoreMLModel(for: Inceptionv3().model) else { return }
        let request = VNCoreMLRequest(model: model) { (finishedReq, err) in
            
            //perhaps check the err
            
            //            print(finishedReq.results)
            
            //            guard let results = finishedReq.results as? [VNClassificationObservation] else { return }
            
            guard let rresults = finishedReq.results as? [VNClassificationObservation] else { return }
            self.results = rresults
            guard let firstObservation = self.results.first else { return }
            
//            print(firstObservation.identifier, firstObservation.confidence)
            
            DispatchQueue.main.async {
                self.identifierLabel.text = "\(firstObservation.identifier) \(firstObservation.confidence * 100)"
            }
            
        }
        
        try? VNImageRequestHandler(cvPixelBuffer: pixelBuffer, options: [:]).perform([request])
    }
    
    @IBAction func takephototapped(_sender: Any) {
        self.photoresults.append(self.results)
//        print("for simple test")
//        print(self.photoresults)
    }
    @IBAction func confirmtapped(_sender: Any) {
//        print(self.photoresults)
//        print("hello")
        
        //实例化一个登陆界面
        let loginView = SelectTableViewController()
        loginView.photoClassifierResults = photoresults
        //从下弹出一个界面作为登陆界面，completion作为闭包，可以写一些弹出loginView时的一些操作
        self.present(loginView, animated: true, completion: nil)
        
    }
    
//    override func viewWillAppear(_ animated: Bool) {
//        model = Inceptionv3()
//    }
//
//    override func didReceiveMemoryWarning() {
//        super.didReceiveMemoryWarning()
//        // Dispose of any resources that can be recreated.
//    }
//
//    @IBAction func camera(_ sender: Any) {
//
//        if !UIImagePickerController.isSourceTypeAvailable(.camera) {
//            return
//        }
//
//        let cameraPicker = UIImagePickerController()
//        cameraPicker.delegate = self
//        cameraPicker.sourceType = .camera
//        cameraPicker.allowsEditing = false
//
//        present(cameraPicker, animated: true)
//    }
//
//    @IBAction func openLibrary(_ sender: Any) {
//        let picker = UIImagePickerController()
//        picker.allowsEditing = false
//        picker.delegate = self
//        picker.sourceType = .photoLibrary
//        present(picker, animated: true)
//    }
    
}

//extension FirstViewController: UIImagePickerControllerDelegate {
//    func imagePickerControllerDidCancel(_ picker: UIImagePickerController) {
//        dismiss(animated: true, completion: nil)
//    }
//    
//    func imagePickerController(_ picker: UIImagePickerController, didFinishPickingMediaWithInfo info: [String : Any]) {
//        
//        picker.dismiss(animated: true)
//        classifier.text = "Analyzing Image..."
//        guard let image = info["UIImagePickerControllerOriginalImage"] as? UIImage else {
//            return
//        } //1
//        
//        UIGraphicsBeginImageContextWithOptions(CGSize(width: 299, height: 299), true, 2.0)
//        image.draw(in: CGRect(x: 0, y: 0, width: 299, height: 299))
//        let newImage = UIGraphicsGetImageFromCurrentImageContext()!
//        UIGraphicsEndImageContext()
//        
//        let attrs = [kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue, kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue] as CFDictionary
//        var pixelBuffer : CVPixelBuffer?
//        let status = CVPixelBufferCreate(kCFAllocatorDefault, Int(newImage.size.width), Int(newImage.size.height), kCVPixelFormatType_32ARGB, attrs, &pixelBuffer)
//        guard (status == kCVReturnSuccess) else {
//            return
//        }
//        
//        CVPixelBufferLockBaseAddress(pixelBuffer!, CVPixelBufferLockFlags(rawValue: 0))
//        let pixelData = CVPixelBufferGetBaseAddress(pixelBuffer!)
//        
//        let rgbColorSpace = CGColorSpaceCreateDeviceRGB()
//        let context = CGContext(data: pixelData, width: Int(newImage.size.width), height: Int(newImage.size.height), bitsPerComponent: 8, bytesPerRow: CVPixelBufferGetBytesPerRow(pixelBuffer!), space: rgbColorSpace, bitmapInfo: CGImageAlphaInfo.noneSkipFirst.rawValue) //3
//        
//        context?.translateBy(x: 0, y: newImage.size.height)
//        context?.scaleBy(x: 1.0, y: -1.0)
//        
//        UIGraphicsPushContext(context!)
//        newImage.draw(in: CGRect(x: 0, y: 0, width: newImage.size.width, height: newImage.size.height))
//        UIGraphicsPopContext()
//        CVPixelBufferUnlockBaseAddress(pixelBuffer!, CVPixelBufferLockFlags(rawValue: 0))
//        imageView.image = newImage
//        
//        // Core ML
//        guard let prediction = try? model.prediction(image: pixelBuffer!) else {
//            return
//        }
//        
//        classifier.text = "I think this is a \(prediction.classLabel)."
//    }
//}

